{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189508c6",
   "metadata": {},
   "source": [
    "\n",
    "# Battery Failure Prediction – Databricks Lakehouse Demo\n",
    "\n",
    "This notebook demonstrates an end-to-end mini-pipeline for **lithium-ion battery test data** using Databricks Lakehouse:\n",
    "\n",
    "1. Load CSV test data (field/vendor returns)\n",
    "2. Clean & cast columns\n",
    "3. Save as Delta tables (Bronze → Silver → Gold)\n",
    "4. Train a simple classification model to predict `FailFlag`\n",
    "5. Log metrics with MLflow and visualize predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70586c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Path to your uploaded file (adjust path for your environment)\n",
    "raw_path = \"/FileStore/tables/sample_battery_data.csv\"\n",
    "\n",
    "raw_df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .csv(raw_path)\n",
    ")\n",
    "\n",
    "display(raw_df)\n",
    "print(\"Row count:\", raw_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a23bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean and cast data\n",
    "df = (\n",
    "    raw_df\n",
    "    .withColumnRenamed(\"voltage\", \"Voltage\")\n",
    "    .withColumnRenamed(\"temperature\", \"Temperature\")\n",
    "    .withColumnRenamed(\"capacity\", \"Capacity\")\n",
    "    .withColumnRenamed(\"fail_flag\", \"FailFlag\")\n",
    "    .select(\"Voltage\", \"Temperature\", \"Capacity\", \"FailFlag\")\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"Voltage\", col(\"Voltage\").cast(\"double\"))\n",
    "    .withColumn(\"Temperature\", col(\"Temperature\").cast(\"double\"))\n",
    "    .withColumn(\"Capacity\", col(\"Capacity\").cast(\"double\"))\n",
    "    .withColumn(\"FailFlag\", col(\"FailFlag\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "display(df.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save data to Delta tables (Bronze and Silver layers)\n",
    "bronze_path = \"/mnt/battery_demo/bronze/battery_raw_delta\"\n",
    "silver_path = \"/mnt/battery_demo/silver/battery_clean_delta\"\n",
    "\n",
    "raw_df.write.mode(\"overwrite\").format(\"delta\").save(bronze_path)\n",
    "df.write.mode(\"overwrite\").format(\"delta\").save(silver_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cb7eb",
   "metadata": {},
   "source": [
    "\n",
    "### Register Delta Tables in Databricks SQL\n",
    "Use this SQL in a `%sql` cell:\n",
    "```sql\n",
    "CREATE DATABASE IF NOT EXISTS battery_demo;\n",
    "\n",
    "DROP TABLE IF EXISTS battery_demo.battery_raw_delta;\n",
    "DROP TABLE IF EXISTS battery_demo.battery_clean_delta;\n",
    "\n",
    "CREATE TABLE battery_demo.battery_raw_delta\n",
    "USING DELTA\n",
    "LOCATION '/mnt/battery_demo/bronze/battery_raw_delta';\n",
    "\n",
    "CREATE TABLE battery_demo.battery_clean_delta\n",
    "USING DELTA\n",
    "LOCATION '/mnt/battery_demo/silver/battery_clean_delta';\n",
    "\n",
    "SELECT * FROM battery_demo.battery_clean_delta LIMIT 20;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "feature_cols = [\"Voltage\", \"Temperature\", \"Capacity\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "assembled_df = assembler.transform(df).na.drop()\n",
    "\n",
    "train_df, test_df = assembled_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"FailFlag\")\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "predictions = lr_model.transform(test_df)\n",
    "display(predictions.select(\"Voltage\",\"Temperature\",\"Capacity\",\"FailFlag\",\"probability\",\"prediction\"))\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"FailFlag\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"Test AUC:\", auc)\n",
    "\n",
    "mlflow.set_experiment(\"/Users/\" + spark.sql(\"SELECT current_user()\").collect()[0][0] + \"/battery_failure_demo\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"battery_lr_model\"):\n",
    "    mlflow.log_metric(\"test_auc\", auc)\n",
    "    mlflow.spark.log_model(lr_model, \"model\")\n",
    "    mlflow.log_param(\"features\", \",\".join(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c3cf4",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "- Add additional features (e.g., site ID, battery model, cycle count)\n",
    "- Try more advanced models (Random Forest, Gradient Boosted Trees)\n",
    "- Build a dashboard in Databricks SQL to visualize results\n",
    "- Schedule daily retraining jobs or integrate with APIs for real-time scoring\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
